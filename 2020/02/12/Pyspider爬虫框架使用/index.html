<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-flash.min.css?v=1.0.2">
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.4.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: true,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="1. 介绍PySpider 是一个基于 Python 的爬虫框架，也就是使用该框架需要懂得一定的 Python 语言。关于 PySpider 的中文文档可以访问 pyspider中文文档。 我们可以在 PySpider 提供的界面上编写和运行 Python 脚本，同时也支持 MySQL, MongoDB, Redis, SQLite, Elasticsearch各种数据库引擎。本文档将实现将 v2">
<meta name="keywords" content="Python,爬虫">
<meta property="og:type" content="article">
<meta property="og:title" content="Pyspider爬虫框架使用">
<meta property="og:url" content="https://ShotoZheng.github.io/2020/02/12/Pyspider爬虫框架使用/index.html">
<meta property="og:site_name" content="鱼肚白不是鱼">
<meta property="og:description" content="1. 介绍PySpider 是一个基于 Python 的爬虫框架，也就是使用该框架需要懂得一定的 Python 语言。关于 PySpider 的中文文档可以访问 pyspider中文文档。 我们可以在 PySpider 提供的界面上编写和运行 Python 脚本，同时也支持 MySQL, MongoDB, Redis, SQLite, Elasticsearch各种数据库引擎。本文档将实现将 v2">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581499599686.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581499780494.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581499922917.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581501330882.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581504896133.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581519090597.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581519393116.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581519623677.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581561253385.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581561399620.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581561492558.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581562027881.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581562276252.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581563817457.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581564006425.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581564452748.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581564525041.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581564556595.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581564674701.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581564828345.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581564978045.png">
<meta property="og:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581564947116.png">
<meta property="og:updated_time" content="2020-02-13T03:44:02.347Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Pyspider爬虫框架使用">
<meta name="twitter:description" content="1. 介绍PySpider 是一个基于 Python 的爬虫框架，也就是使用该框架需要懂得一定的 Python 语言。关于 PySpider 的中文文档可以访问 pyspider中文文档。 我们可以在 PySpider 提供的界面上编写和运行 Python 脚本，同时也支持 MySQL, MongoDB, Redis, SQLite, Elasticsearch各种数据库引擎。本文档将实现将 v2">
<meta name="twitter:image" content="https://shotozheng.github.io/2020/02/12/Pyspider爬虫框架使用/1581499599686.png">
  <link rel="canonical" href="https://ShotoZheng.github.io/2020/02/12/Pyspider爬虫框架使用/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Pyspider爬虫框架使用 | 鱼肚白不是鱼</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  <!--音乐播放器-->
  <link rel="stylesheet" href="/dist/APlayer.min.css">
  <div id="aplayer"></div>
  <script type="text/javascript" src="/dist/APlayer.min.js"></script>
  <script type="text/javascript" src="/dist/music.js"></script>

  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">鱼肚白不是鱼</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">笨鸟先飞</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-网站">
      
    

    <a href="/网站/" rel="section"><i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>网站</a>

  </li>
      <li class="menu-item menu-item-search">
        <a href="javascript:;" class="popup-trigger">
        
          <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
      </li>
    
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="https://ShotoZheng.github.io/2020/02/12/Pyspider爬虫框架使用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="郑松涛">
      <meta itemprop="description" content="积跬步，至千里">
      <meta itemprop="image" content="/images/kanieki.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="鱼肚白不是鱼">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">Pyspider爬虫框架使用

          
        </h1>

        <div class="post-meta">

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2020-02-12 15:53:33" itemprop="dateCreated datePublished" datetime="2020-02-12T15:53:33+08:00">2020-02-12</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-13 11:44:02" itemprop="dateModified" datetime="2020-02-13T11:44:02+08:00">2020-02-13</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/爬虫/" itemprop="url" rel="index"><span itemprop="name">爬虫</span></a></span>

                
                
              
            </span>
          

          
            <span class="post-meta-item" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/02/12/Pyspider爬虫框架使用/#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2020/02/12/Pyspider爬虫框架使用/" itemprop="commentCount"></span></a>
  </span>
  
  
          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
              
                <span class="post-meta-item-text">本文字数：</span>
              
              <span>9.5k</span>
            </span>
          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
              
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              
              <span>9 分钟</span>
            </span>
          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h2><p>PySpider 是一个基于 Python 的爬虫框架，也就是使用该框架需要懂得一定的 Python 语言。关于 PySpider 的中文文档可以访问 <a href="https://www.cntofu.com/book/156/index.html" target="_blank" rel="noopener">pyspider中文文档</a>。</p>
<p>我们可以在 PySpider 提供的界面上编写和运行 Python 脚本，同时也支持 MySQL, MongoDB, Redis, SQLite, Elasticsearch各种数据库引擎。本文档将实现将 v2ex 中爬取的数据存放在 MySQL 数据库中。下面就先开始从 PySpider 的环境安装开始吧。</p>
<a id="more"></a>

<h2 id="2-环境安装"><a href="#2-环境安装" class="headerlink" title="2. 环境安装"></a>2. 环境安装</h2><p>下面介绍一下在 Windows 10 中 PySpider 的安装，当然由于 PySpider 是基于 Python 的，所以也自然需要先安装 Python，这里我们选择 Python 2.7  32bit。在安装 PySpider 的安装过程中还会涉及到许多插件的安装以及配置的修改。下面就开始一步一步的安装 PySpider 吧。 </p>
<h3 id="2-1-Python-2-7-安装"><a href="#2-1-Python-2-7-安装" class="headerlink" title="2.1 Python 2.7 安装"></a>2.1 Python 2.7 安装</h3><ol>
<li><p>首先是到<a href="https://www.python.org/downloads/release/python-2712" target="_blank" rel="noopener">官网</a>中下载对应的 Python 安装包，具体位置如下所示：</p>
<p> <img src="/2020/02/12/Pyspider爬虫框架使用/1581499599686.png" alt></p>
</li>
<li><p>然后运行一直 next 即可，然后就是进行环境变量的配置。在 path 中添加如下环境变量，具体路径根据具体情况而定。</p>
<p> <img src="/2020/02/12/Pyspider爬虫框架使用/1581499780494.png" alt></p>
</li>
<li><p>打开命令行窗口，输入 ‘python -V’，如果可以打印版本号，说明 Python 已经安装成功。如下所示：</p>
</li>
</ol>
<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581499922917.png" alt></p>
<h3 id="2-2-PySpider-安装"><a href="#2-2-PySpider-安装" class="headerlink" title="2.2 PySpider 安装"></a>2.2 PySpider 安装</h3><ol>
<li><p><strong>pip 安装</strong>：pip 是 Python 包管理工具，该工具提供了对Python 包的查找、下载、安装、卸载的功能。Python 2.7.9 +  或 Python 3.4+  以上版本都自带 pip 工具。我们可以通过如下命令判断 pip 是否已经安装。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip -V</span><br></pre></td></tr></table></figure>

<p> 如果没有进行 pip 的安装，可以通过如下命令进行安装。用哪个版本的 Python 运行安装脚本，pip 就被关联到哪个版本。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py   # 下载安装脚本</span><br><span class="line">$ sudo python get-pip.py    # 运行安装脚本</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>pycURL 安装</strong>：一般情况下在安装 python 的时候会自动安装好 pycURL。如果没有，那么首先需要到该<a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/" target="_blank" rel="noopener">网站</a>中下载与 python 对应版本的安装文件，具体如下所示。这里我们选择  2.7 32bit 的版本。</p>
<p> <img src="/2020/02/12/Pyspider爬虫框架使用/1581501330882.png" alt></p>
<p> 然后在 cmd 窗口中输入如下命令完成 pycURL 的安装：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install 文件全路径</span><br><span class="line">比如：</span><br><span class="line">pip install D:\pycurl-7.43.0.3-cp27-cp27m-win32.whl</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>lxml 安装</strong>：同安装 pycURL 一样，我们需要安装 lxml。先到该<a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/" target="_blank" rel="noopener">网站</a>中下载与 python 对应版本的安装文件，具体如下所示。这里我们同样选择  2.7 32bit 的版本。</p>
<p> <img src="/2020/02/12/Pyspider爬虫框架使用/1581504896133.png" alt></p>
</li>
<li><p><strong>VCForPython27.msi 和 mysql-connector-c-6.0.2-winx64.msi 安装</strong>，windows 直接双击运行即可。</p>
</li>
<li><p><strong>mysql-python 安装</strong>：安装的具体命令如下所示：</p>
   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install mysql-python</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>phantomjs 安装</strong>：从<a href="http://phantomjs.org/download.html" target="_blank" rel="noopener">官网</a>中下载安装包，解压后将phantomjs.exe文件放到python根目录。</p>
</li>
<li><p>pyspider 安装：如下所示，我们可以使用如下命令安装 pyspider，具体命令如下：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyspider</span><br></pre></td></tr></table></figure>

<p> 安装的时候，发生了如下的错误：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Deprecated option &apos;domaincontroller&apos;: use &apos;http_authenticator.domain_controller&apos; instead.</span><br></pre></td></tr></table></figure>

<p> 解决的方法是找到 pyspider 的安装位置（’Python27\Lib\site-packages\pyspider\webui\webdav.py’），修改文件的第 209 行即可。即把’’domaincontroller’: NeedAuthController(app),’ 改为如下语句：</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'http_authenticator'</span>:&#123;</span><br><span class="line">    <span class="string">'HTTPAuthenticator'</span>:NeedAuthController(app),</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>

<p> 修改完成之后，还发生了如下的错误。本人目前在 Github 项目中的 issues 中或者在网上并没有找到相关的解决办法</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ImportError: cannot import name DispatcherMiddleware</span><br></pre></td></tr></table></figure>

<p> 根据报错信息，修改了 ‘Python27\Lib\site-packages\pyspider\webui\app.py’ 该文件，将发生错误的地方使用 try catch 进行捕获，这并不会影响 PySpider 框架的运行。</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> .webdav <span class="keyword">import</span> dav_app</span><br><span class="line"><span class="keyword">except</span> ImportError <span class="keyword">as</span> e:</span><br><span class="line">    logger.warning(<span class="string">'WebDav interface not enabled: %r'</span>, e)</span><br><span class="line">    dav_app = <span class="literal">None</span></span><br><span class="line"><span class="comment"># 第 63 行的位置</span></span><br><span class="line"><span class="keyword">if</span> dav_app:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">from</span> werkzeug.wsgi <span class="keyword">import</span> DispatcherMiddleware</span><br><span class="line">        application = DispatcherMiddleware(application, &#123;</span><br><span class="line">            <span class="string">'/dav'</span>: dav_app</span><br><span class="line">        &#125;)</span><br><span class="line">    <span class="keyword">except</span> ImportError <span class="keyword">as</span> e:</span><br><span class="line">        logger.warning(<span class="string">''</span>)</span><br></pre></td></tr></table></figure>

<p> 至此，PySpider 框架的安装终于完成了，我们可以在命令行窗口中输入 ‘pyspider all’ 运行 PySpider 框架，并在浏览器上输入如下 URL 访问 PySpider：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://localhost:5000</span><br></pre></td></tr></table></figure>

<p> 访问后，浏览器会显示如下界面，下面我们开始介绍 PySpider 框架的使用。</p>
<p> <img src="/2020/02/12/Pyspider爬虫框架使用/1581519090597.png" alt></p>
</li>
</ol>
<h2 id="3-PySpider-使用"><a href="#3-PySpider-使用" class="headerlink" title="3. PySpider 使用"></a>3. PySpider 使用</h2><h3 id="3-1-项目创建"><a href="#3-1-项目创建" class="headerlink" title="3.1 项目创建"></a>3.1 项目创建</h3><p>如下所示，进行爬虫项目的创建，具体步骤如下所示：</p>
<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581519393116.png" alt></p>
<p>项目创建完成之后，会进入如下页面，左侧是查看运行结果的地方，右侧则是编写具体的 python 脚本位置。</p>
<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581519623677.png" alt></p>
<h3 id="3-2-PySpider-语法"><a href="#3-2-PySpider-语法" class="headerlink" title="3.2 PySpider 语法"></a>3.2 PySpider 语法</h3><h4 id="3-2-1-PySpider-原生示例"><a href="#3-2-1-PySpider-原生示例" class="headerlink" title="3.2.1 PySpider 原生示例"></a>3.2.1 PySpider 原生示例</h4><p>查看上图，右侧是有默认生成的脚本代码。对于代码的含义具体如下的注释说明：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 告诉操作系统到 usr/bin/env 里查找 python 的安装路径，再调用对应路径下的解释器程序完成操作</span></span><br><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># python 脚本支持的编码</span></span><br><span class="line"><span class="comment"># -*- encoding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># Created on 2020-02-12 22:56:46</span></span><br><span class="line"><span class="comment"># Project: test</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspider.libs.base_handler <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Handler</span><span class="params">(BaseHandler)</span>:</span></span><br><span class="line">    crawl_config = &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 注解表明每 24 * 60 分钟即一天只爬取一次</span></span><br><span class="line"><span class="meta">    @every(minutes=24 * 60)</span></span><br><span class="line">    <span class="comment"># crawl方法中的第一个参数是爬取网站的入口地址，第二个参数则是调用的方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_start</span><span class="params">(self)</span>:</span> </span><br><span class="line">        self.crawl(<span class="string">'https://www.v2ex.com'</span>, callback=self.index_page)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @config(age=10 * 24 * 60 * 60)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">index_page</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment"># doc 内的参数是爬取网站的第二个入口位置，比如 a[href^="https://v2ex.com/?tab="]</span></span><br><span class="line">        <span class="comment"># a[href^="http"]表示 href 属性以 http 开头的 a 元素</span></span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">'a[href^="http"]'</span>).items():</span><br><span class="line">            <span class="comment"># 调用 detail_page 方法</span></span><br><span class="line">            self.crawl(each.attr.href, callback=self.detail_page)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @config(priority=2)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detail_page</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="comment"># 返回爬取出来的 url 和 title 值</span></span><br><span class="line">            <span class="string">"url"</span>: response.url,</span><br><span class="line">            <span class="string">"title"</span>: response.doc(<span class="string">'title'</span>).text(),</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<h4 id="3-2-2-PyQuery-之-Response"><a href="#3-2-2-PyQuery-之-Response" class="headerlink" title="3.2.2 PyQuery 之 Response"></a>3.2.2 PyQuery 之 Response</h4><p><a href="https://pythonhosted.org/pyquery/api.html" target="_blank" rel="noopener">PyQuery</a> 库是 JQuery 的 Python 实现，能够以 JQuery 的语法来操作解析 HTML 文档，易用性和解析速度都很好，和它差不多的还有BeautifulSoup，都是用来解析的。</p>
<p>在 PySpider 的使用中，Response 对象的使用是比较频繁的。PySpider 的<a href="http://docs.pyspider.org/en/latest/apis/Response/" target="_blank" rel="noopener">官网</a>就有关于 Response 的使用。下面我们仅列出 Response 常用的几个方法，具体如下所示：</p>
<table>
<thead>
<tr>
<th>方法/属性</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>doc</td>
<td>Html 查找 PyQuery 对象</td>
</tr>
<tr>
<td>url</td>
<td>对应链接</td>
</tr>
<tr>
<td>text</td>
<td>文本</td>
</tr>
<tr>
<td>header</td>
<td>返回的header</td>
</tr>
<tr>
<td>cookies</td>
<td>下发cookie</td>
</tr>
</tbody></table>
<h4 id="3-2-3-CSS-选择器"><a href="#3-2-3-CSS-选择器" class="headerlink" title="3.2.3 CSS 选择器"></a>3.2.3 CSS 选择器</h4><p>使用 PySpider 编写 Python 爬虫脚本的时候，需要使用到 CSS 选择器，CSS 选择器的作用即是用于解析页面上的 html 元素，关于 CSS 选择器的参考资料可以访问该<a href="http://www.w3school.com.cn/cssref/css_selectors.asp" target="_blank" rel="noopener">网站</a>。 下面我罗列了常用 CSS 选择器语法，具体如下所示：</p>
<table>
<thead>
<tr>
<th>选择器</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>.class</td>
<td>class=“class”</td>
</tr>
<tr>
<td>#id</td>
<td>&lt;p id=”id”&gt;</td>
</tr>
<tr>
<td>div.inner</td>
<td>&lt;div class=”inner”&gt;</td>
</tr>
<tr>
<td>a[href^=“http://”]</td>
<td>带http开头href的a元素</td>
</tr>
<tr>
<td>p div</td>
<td>p元素下的div元素（不必父子）</td>
</tr>
<tr>
<td>p&gt;div&gt;span</td>
<td>p元素下的div元素下的span</td>
</tr>
<tr>
<td>[target=_blank]</td>
<td>Target=_blank</td>
</tr>
</tbody></table>
<h3 id="3-3-爬虫实例"><a href="#3-3-爬虫实例" class="headerlink" title="3.3 爬虫实例"></a>3.3 爬虫实例</h3><p>下面我们将爬取 v2ex 网站中帖子的标题和内容，爬虫的代码具体如下所示，具体的爬虫实现需要参考爬取的网页 HTML 结构：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- encoding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># Created on 2020-02-11 22:30:08</span></span><br><span class="line"><span class="comment"># Project: v2ex</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspider.libs.base_handler <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> MySQLdb</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Handler</span><span class="params">(BaseHandler)</span>:</span></span><br><span class="line">    crawl_config = &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 初始化连接数据库</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 参数分别为本地IP、数据库用户名、数据库密码、数据库名称、编码</span></span><br><span class="line">        self.db = MySQLdb.connect(<span class="string">'localhost'</span>, <span class="string">'root'</span>, <span class="string">'abc123'</span>, <span class="string">'izhihu'</span>, charset=<span class="string">'utf8'</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 添加问题</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_question</span><span class="params">(self, title, content)</span>:</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment">## 获取数据库游标</span></span><br><span class="line">            cursor = self.db.cursor()</span><br><span class="line">            sql = <span class="string">'insert into question(title, content, user_id, created_date, comment_count) values("%s", "%s", %d, now(), 0)'</span> % (title, content, random.randint(<span class="number">1</span>,<span class="number">10</span>))</span><br><span class="line">            <span class="keyword">print</span> sql</span><br><span class="line">            cursor.execute(sql)</span><br><span class="line">            self.db.commit()</span><br><span class="line">        <span class="keyword">except</span> Exception, e:</span><br><span class="line">            <span class="keyword">print</span> e</span><br><span class="line">            self.db.rollback()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># @every(minutes=24 * 60) # 限制每天只执行一次</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_start</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># validate_cert=False 避免因为 SSL 安全机制导致的访问限制</span></span><br><span class="line">        self.crawl(<span class="string">'https://v2ex.com/'</span>, callback=self.index_page,validate_cert=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @config(age=10 * 24 * 60 * 60)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">index_page</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">'a[href^="https://v2ex.com/?tab="]'</span>).items():</span><br><span class="line">            self.crawl(each.attr.href, callback=self.tab_page, validate_cert=<span class="literal">False</span>)</span><br><span class="line">            </span><br><span class="line"><span class="meta">    @config(priority=2)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tab_page</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">'a[href^="https://v2ex.com/go/"]'</span>).items():</span><br><span class="line">            self.crawl(each.attr.href, callback=self.board_page, validate_cert=<span class="literal">False</span>)</span><br><span class="line">            </span><br><span class="line"><span class="meta">    @config(priority=2)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">board_page</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">'a[href^="https://v2ex.com/t/"]'</span>).items():</span><br><span class="line">            <span class="comment"># 去掉路径形如 #reply12 的后缀</span></span><br><span class="line">            url = each.attr.href</span><br><span class="line">            <span class="keyword">if</span> (url.find(<span class="string">'#reply'</span>) &gt; <span class="number">0</span>):</span><br><span class="line">                url = url[<span class="number">0</span>:url.find(<span class="string">'#'</span>)] <span class="comment"># 类似 Java 的 subString 方法</span></span><br><span class="line">            self.crawl(url, callback=self.detail_page, validate_cert=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment">## 翻页,然后回调本身的方法</span></span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">'a.page_normal'</span>).items():</span><br><span class="line">            self.crawl(each.attr.href, callback = self.board_page, validate_cert=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @config(priority=2)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detail_page</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        title = response.doc(<span class="string">'h1'</span>).text()</span><br><span class="line">        content = response.doc(<span class="string">"div.markdown_body"</span>).html()</span><br><span class="line">        <span class="comment">## 添加问题</span></span><br><span class="line">        self.add_question(title, content)</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">"url"</span> : response.url,</span><br><span class="line">            <span class="string">"title"</span>: response.doc(<span class="string">'title'</span>).text()</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<p>下面我们结合这 v2ex 网站来分析一下上述脚本的具体作用，查看如下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@config(age=10 * 24 * 60 * 60)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index_page</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">'a[href^="https://v2ex.com/?tab="]'</span>).items():</span><br><span class="line">        self.crawl(each.attr.href, callback=self.tab_page, validate_cert=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p>‘a[href^=”<a href="https://v2ex.com/?tab=&quot;]&#39;" target="_blank" rel="noopener">https://v2ex.com/?tab=&quot;]&#39;</a> 表示爬取页面的第二个入口，即 v2ex 主页上的一个标签栏，具体如下图所示：</p>
<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581561253385.png" alt></p>
<p>观察如下代码，同上面的一样，’a[href^=”<a href="https://v2ex.com/go/&quot;]&#39;是爬虫的第三个入口，以" target="_blank" rel="noopener">https://v2ex.com/go/&quot;]&#39;是爬虫的第三个入口，以</a> go 开头。具体如下图所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@config(priority=2)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tab_page</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">'a[href^="https://v2ex.com/go/"]'</span>).items():</span><br><span class="line">        self.crawl(each.attr.href, callback=self.board_page, validate_cert=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581561399620.png" alt></p>
<p>观察如下代码，’a[href^=”<a href="https://v2ex.com/t/&quot;]&#39;" target="_blank" rel="noopener">https://v2ex.com/t/&quot;]&#39;</a> 为第四个入口，这里已经到达具体的文章链接了，如下图所示。对于文章链接我们这里需要将形如 #reply12 的后缀去掉，然后在调用 detail_page 方法获取我们需要的数据，即帖子的标题和内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@config(priority=2)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">board_page</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">'a[href^="https://v2ex.com/t/"]'</span>).items():</span><br><span class="line">        <span class="comment"># 去掉路径形如 #reply12 的后缀</span></span><br><span class="line">        url = each.attr.href</span><br><span class="line">        <span class="keyword">if</span> (url.find(<span class="string">'#reply'</span>) &gt; <span class="number">0</span>):</span><br><span class="line">            url = url[<span class="number">0</span>:url.find(<span class="string">'#'</span>)] <span class="comment"># 类似 Java 的 subString 方法</span></span><br><span class="line">        self.crawl(url, callback=self.detail_page, validate_cert=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment">## 翻页,然后回调本身的方法</span></span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">'a.page_normal'</span>).items():</span><br><span class="line">        self.crawl(each.attr.href, callback = self.board_page, validate_cert=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581561492558.png" alt></p>
<p>观察上面涉及翻页然后回调本身的方法的代码，这里涉及到翻页的操作，具体体现如下图所示。每一页都是由 p = 页码 来表示。要进行具体的翻页操作，自然需要获取翻页的链接。我们可以查看页面元素，如图2所示。我们发现翻页链接都是存放在 a 标签 calss 名为 page_normal 下的，因此我们可以通过 ‘response.doc(‘a.page_normal’)’ 来获取。</p>
<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581562027881.png" alt="图1"></p>
<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581562276252.png" alt="图2"></p>
<p>观察如下代码，这是爬虫的最后一步，在该方法中可以获取帖子的标题和内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@config(priority=2)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detail_page</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    title = response.doc(<span class="string">'h1'</span>).text()</span><br><span class="line">    content = response.doc(<span class="string">"div.markdown_body"</span>).html()</span><br><span class="line">    <span class="comment">## 添加问题，然后插入数据库中</span></span><br><span class="line">    self.add_question(title, content)</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">"url"</span> : response.url,</span><br><span class="line">        <span class="string">"title"</span>: response.doc(<span class="string">'title'</span>).text()</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>其中我们可以通过 response.doc(‘h1’).text() 获取帖子的标题，这需要根据具体的页面元素而定。v2ex 的页面定义如下图所示：</p>
<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581563817457.png" alt></p>
<p>同理我们通过 response.doc(“div.markdown_body”).html() 获取帖子的内容，帖子的内容具体即存放在 class 为 markdown_body 的 div 下中，具体如下图所示：</p>
<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581564006425.png" alt></p>
<h3 id="3-4-数据爬取"><a href="#3-4-数据爬取" class="headerlink" title="3.4 数据爬取"></a>3.4 数据爬取</h3><p>在 python 爬虫脚本编写完成之后，需要进行界面的操作，以此进行数据的爬取。在 PySpider 界面操作的时候，可以分为手动点击数据爬取和自动的爬取。下面就讲解一下相关的内容。</p>
<h4 id="3-4-1-手动操作"><a href="#3-4-1-手动操作" class="headerlink" title="3.4.1 手动操作"></a>3.4.1 手动操作</h4><p>如下所示，点击 run 之后，界面下方会出现 follows 的红点标识：</p>
<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581564452748.png" alt></p>
<p>接着点击 follows ，然后点击执行，具体如下图所示：</p>
<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581564525041.png" alt></p>
<p>如下图所示，页面显示的内容是根据我们编写的爬虫脚本代码进行的，当进入的具体的帖子页面的时候，则完成数据的入库操作。</p>
<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581564556595.png" alt></p>
<p>如下图所示，数据完成入库操作，打印出执行的 SQL 语句。</p>
<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581564674701.png" alt></p>
<h4 id="3-4-2-自动操作"><a href="#3-4-2-自动操作" class="headerlink" title="3.4.2 自动操作"></a>3.4.2 自动操作</h4><p>当然我们也可以让 PySpider 进行数据的自动爬取，如下图所示，更改执行状态，然后点击 run 进行执行，并点击 Active Tasks 查看具体的执行过程。</p>
<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581564828345.png" alt></p>
<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581564978045.png" alt="执行过程任务列表"></p>
<p>我们还可以更改爬取的频率，如下图所示，我将频率更改为每秒钟 0.1 次：</p>
<p><img src="/2020/02/12/Pyspider爬虫框架使用/1581564947116.png" alt></p>

    </div>

    
    
    

    <div>
    
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:24px;">------ 本文结束------</div>
    
</div>

    
    </div>
        
      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a>
            
              <a href="/tags/爬虫/" rel="tag"><i class="fa fa-tag"></i> 爬虫</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2020/01/05/（二）MyBatis学习笔记-HelloWorld/" rel="next" title="（二）MyBatis学习笔记-HelloWorld">
                  <i class="fa fa-chevron-left"></i> （二）MyBatis学习笔记-HelloWorld
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2020/03/06/Solr全文搜索服务器的使用/" rel="prev" title="Solr全文搜索服务器的使用">
                  Solr全文搜索服务器的使用 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          
    
    <div class="comments" id="comments"></div>
  

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-介绍"><span class="nav-text">1. 介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-环境安装"><span class="nav-text">2. 环境安装</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-Python-2-7-安装"><span class="nav-text">2.1 Python 2.7 安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-PySpider-安装"><span class="nav-text">2.2 PySpider 安装</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-PySpider-使用"><span class="nav-text">3. PySpider 使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-项目创建"><span class="nav-text">3.1 项目创建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-PySpider-语法"><span class="nav-text">3.2 PySpider 语法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-1-PySpider-原生示例"><span class="nav-text">3.2.1 PySpider 原生示例</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-2-PyQuery-之-Response"><span class="nav-text">3.2.2 PyQuery 之 Response</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-3-CSS-选择器"><span class="nav-text">3.2.3 CSS 选择器</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-爬虫实例"><span class="nav-text">3.3 爬虫实例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-数据爬取"><span class="nav-text">3.4 数据爬取</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-4-1-手动操作"><span class="nav-text">3.4.1 手动操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-4-2-自动操作"><span class="nav-text">3.4.2 自动操作</span></a></li></ol></li></ol></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/kanieki.png"
      alt="郑松涛">
  <p class="site-author-name" itemprop="name">郑松涛</p>
  <div class="site-description" itemprop="description">积跬步，至千里</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">166</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">54</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        <span class="site-state-item-count">35</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/ShotoZheng" title="GitHub &rarr; https://github.com/ShotoZheng" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:shotozheng@163.com" title="E-Mail &rarr; mailto:shotozheng@163.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">郑松涛</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">942k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">14:17</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.4.0</div>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  
    <span class="post-meta-divider">|</span>
  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>












        
      </div>
    </footer>
  </div>

  


  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
<script src="/js/utils.js?v=7.4.0"></script><script src="/js/motion.js?v=7.4.0"></script>
<script src="/js/schemes/pisces.js?v=7.4.0"></script>
<script src="/js/next-boot.js?v=7.4.0"></script>



  








  <script src="/js/local-search.js?v=7.4.0"></script>










<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme: 'forest',
      logLevel: 3,
      flowchart: { curve: 'linear' },
      gantt: { axisFormat: '%m/%d/%Y' },
      sequence: { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>




  

  

  

  


<script>
NexT.utils.getScript('//cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'd6TU9yIpopEhNQKUras2D3Nr-gzGzoHsz',
    appKey: 'CJpUierMSXBHmTo6mJ8G1KO1',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn',
    path: location.pathname
  });
}, window.Valine);
</script>

</body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/clicklove.js"></script>
<!--看板娘-->
<script src="/live2d-widget/autoload.js"></script>
